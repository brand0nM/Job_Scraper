{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8252cb",
   "metadata": {},
   "source": [
    "# Daily Jobs Web Scrapper\n",
    "3 titles I want to search across 4 platforms and google: Dice, Indeed, Monster, and Ziprecruiter.\n",
    "Can easily Create 5 seperate case class objects that extend a \"Search\" Abstraction, \n",
    "meaning each website will have to manual be instantiated\n",
    "\n",
    "## Vision\n",
    "Want to train an ai to webscrape unique websites (After:: already  exist routine based): \n",
    "\n",
    "### Obvious Limitations\n",
    "- Bott Checks, will have to first create an algorithm that can pass most \"Captcha\". \n",
    "\n",
    "- Misidentified parsing information\n",
    "\n",
    "- Invalid Selection Options, misunderstood from bott's perspective\n",
    "\n",
    "- User needed text inputs- outside of myself (Could create my own Brandon chat bott)\n",
    "\n",
    "#### Bott Checks\n",
    "Can have a categorizer for bott checks \n",
    "\n",
    "- Simple catchas can be waited then clicked \n",
    "**Need to start encorparating mouse movements in any scrapes**\n",
    "\n",
    "- Others can be sent back to vm and \"Solved\"- \n",
    "**Need to explore different algos for this probably a lot for most basics (Identify, right-side-up, etc.)**\n",
    "\n",
    "### Conclusion\n",
    "These limitations are vsat enough to put this part of the project on hold at the moment, maybe when I get more experience as a software engineer but this skillset will be pretty.. involved. \n",
    "\n",
    "#### Trouble Shooting\n",
    "Webdriver is shitty.. Most likely you are running this from the M1. \n",
    "\n",
    "First use brew to update your version of webdriver from terminal.\n",
    "For more,\n",
    "[Webdriver](\"https://stackoverflow.com/questions/76727774/selenium-webdriver-chrome-115-stopped-working/76731553#76731553\")\n",
    "\n",
    "    $ python3 -m pip install webdriver-manager \n",
    " \n",
    "Then update Splinter. \n",
    "For more,\n",
    "[Splinter](\"https://splinter.readthedocs.io/en/latest/why.html\")\n",
    "\n",
    "    $ python3 -m pip install splinter\n",
    "    \n",
    "Ideally note book was launched from a conda environment, \n",
    "\n",
    "**In the future start exporting your ymls and keep clean/distinct environment for each project**\n",
    "\n",
    "\n",
    "# Class Based Solution\n",
    "\n",
    "Abstraction, all websites will need\n",
    "\n",
    "- Basic navigation \n",
    "\n",
    "- Filtering of results in the website\n",
    "\n",
    "- Store job metadata as a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30405593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from JobBoard import *\n",
    "from Dice import Dice\n",
    "from Monster import Monster\n",
    "from Indeed import Indeed\n",
    "from LinkedIn import LinkedIn\n",
    "from ZipRecruiter import ZipRecruiter\n",
    "from Google import Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180e756",
   "metadata": {},
   "source": [
    "## Dice\n",
    "May want to consider a tiles approach, taking in all the raw data- unadolterated, then filtering instead of prefiltering on website\n",
    "\n",
    "TODO\n",
    "- Write Class Abstraction, Correctly write aggs and displays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3cd64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "days_ago = 0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "dice_listings = pd.concat([\n",
    "    Dice(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Engineer\", location, days_ago).available_jobs])\n",
    "\n",
    "location = \"remote\"\n",
    "\n",
    "remote_dice_listings = pd.concat([\n",
    "    Dice(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Engineer\", location, days_ago).available_jobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remote_dice_listings\\\n",
    "    .groupby([\"job_title\", \"company\"])\\\n",
    "    .count().reset_index()\n",
    "\n",
    "noSen = noSeniors(df)\n",
    "todays_date = \"Jan8\"\n",
    "\n",
    "noSen.sort_values(\"job_title\").to_csv(\"Remote_Jobs_\"+todays_date+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee34185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dice_listings\\\n",
    "    .groupby([\"job_title\", \"company\"]).sum()\\\n",
    "    .reset_index().sort_values(\"job_title\")\n",
    "\n",
    "noSeniors(df).head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15ba9a",
   "metadata": {},
   "source": [
    "## Indeed\n",
    "\n",
    "TODO\n",
    "\n",
    "- Fix clear sections on location\n",
    "- Integrate scroll and nextpage\n",
    "- Widden Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea54620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "days_ago=0\n",
    "location = \"Centennial\"\n",
    "\n",
    "indeed_listings = pd.concat([\n",
    "    Indeed(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Indeed(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Indeed(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Indeed(\"Data Engineer\", location, days_ago).available_jobs])\\\n",
    "    .reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c61f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_listings\\\n",
    "    .groupby([\"job_title\",\"company\"]).sum()\\\n",
    "    .reset_index().sort_values(\"job_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc375d",
   "metadata": {},
   "source": [
    "## LinkedIn\n",
    "TODO\n",
    "- Figure out next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0081711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "days_ago=0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "## Ran out of testing for today, Brokenish\n",
    "linkedin_jobs = pd.concat([\n",
    "    LinkedIn(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    LinkedIn(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    LinkedIn(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    LinkedIn(\"Data Engineer\", location, days_ago).available_jobs])\\\n",
    "    .reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1d574",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linkedin_jobs.sort_values(\"job_title\").reset_index()[[\"job_title\", \"company\", \"link\"]] # .iloc[7, 2]\n",
    "#     .groupby([\"job_title\",\"company\"]).sum()\\\n",
    "#     .reset_index().sort_values(\"job_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a77bc8",
   "metadata": {},
   "source": [
    "## Zip Recruiter\n",
    "TODO\n",
    "- Next Page\n",
    "- Bott Check in Parrallel, so can handle challenge if served (probably unneccessary if ran on daily cadence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375515e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_ago = 0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "zip_listings = pd.concat([\n",
    "    ZipRecruiter(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    ZipRecruiter(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    ZipRecruiter(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    ZipRecruiter(\"Data Engineer\", location, days_ago).available_jobs])\\\n",
    "    .reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d624cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65239c3",
   "metadata": {},
   "source": [
    "## Monster\n",
    "TODO\n",
    "- Widden Radius\n",
    "- Need to figure out python version errors with webdriver (only runs on Python 3, not python 3.11, could be because of depreciation on newer version- 3.11) find both python env (think alias Python 3 comes from conda) and resolve differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01ce854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Filter Click...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'is_element_visible_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m days_ago \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentennial Colorado\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m monster_listings \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mMonster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSQL Analyst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays_ago\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mavailable_jobs,\\\n\u001b[1;32m      6\u001b[0m     Monster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Analyst\u001b[39m\u001b[38;5;124m\"\u001b[39m, location, days_ago)\u001b[38;5;241m.\u001b[39mavailable_jobs,\\\n\u001b[1;32m      7\u001b[0m     Monster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Scientist\u001b[39m\u001b[38;5;124m\"\u001b[39m, location, days_ago)\u001b[38;5;241m.\u001b[39mavailable_jobs,\\\n\u001b[1;32m      8\u001b[0m     Monster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Engineer\u001b[39m\u001b[38;5;124m\"\u001b[39m, location, days_ago)\u001b[38;5;241m.\u001b[39mavailable_jobs])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mlen\u001b[39m(monster_listings)\n",
      "File \u001b[0;32m~/Desktop/IndepStudy/Projects/Job_Scrapping/Monster.py:58\u001b[0m, in \u001b[0;36mMonster.__init__\u001b[0;34m(self, JobTitle, JobLocation, DaysAgo)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__click__(nav[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclick1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m## Filter Results\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mclicker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Select In-Person (If Non-Remote)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_location\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremote\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/IndepStudy/Projects/Job_Scrapping/Monster.py:12\u001b[0m, in \u001b[0;36mMonster.__init__.<locals>.clicker\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying Filter Click...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(random()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m); \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__click__(nav[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclick2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_element_visible_by_xpath\u001b[49m(nav[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclick3\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFilter Clicked\u001b[39m\u001b[38;5;124m\"\u001b[39m); \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     14\u001b[0m clicker()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'is_element_visible_by_xpath'"
     ]
    }
   ],
   "source": [
    "days_ago = 0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "monster_listings =  pd.concat([\n",
    "    Monster(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Monster(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Monster(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Monster(\"Data Engineer\", location, days_ago).available_jobs])\n",
    "len(monster_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11aa2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Filter Click...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'is_element_visible_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m browser\u001b[38;5;241m.\u001b[39mfind_by_xpath(nav[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclick1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m## Filter Results\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mclicker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mclicker\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(random()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m browser\u001b[38;5;241m.\u001b[39mfind_by_xpath(nav[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclick2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_element_visible_by_xpath\u001b[49m(nav[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclick3\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFilter Clicked\u001b[39m\u001b[38;5;124m\"\u001b[39m); \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m clicker()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'is_element_visible_by_xpath'"
     ]
    }
   ],
   "source": [
    "from Nav import nav\n",
    "def clicker():\n",
    "    print(\"Trying Filter Click...\")\n",
    "    time.sleep(random()*3+2)\n",
    "    browser.find_by_xpath(nav[\"Monster\"][\"click2\"])\n",
    "    if browser.is_element_visible_by_xpath(nav[\"Monster\"][\"click3\"]):\n",
    "        print(\"Filter Clicked\"); return\n",
    "    clicker()\n",
    "    \n",
    "    \n",
    "browser = Browser(\"chrome\")\n",
    "## Navigation\n",
    "start = time.perf_counter()\n",
    "# Visit Dice\n",
    "browser.visit(\"http://www.monster.com\") \n",
    "# Fill Job\n",
    "browser.find_by_css(\"#horizontal-input-one-undefined\").fill(\"poop\")\n",
    "# Fill Job's Location\n",
    "browser.find_by_css(\"#horizontal-input-two-undefined\").fill(\"butt\")\n",
    "# Click on Search\n",
    "browser.find_by_xpath(nav[\"Monster\"][\"click1\"]).click()\n",
    "\n",
    "\n",
    "## Filter Results\n",
    "clicker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0665cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped = pd.DataFrame(monster_listings)\\\n",
    "    .groupby([\"job_title\",\"company\"]).sum()\\\n",
    "    .reset_index().sort_values(\"job_title\")\n",
    "\n",
    "grouped.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.iloc[13, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee39cb",
   "metadata": {},
   "source": [
    "## Google\n",
    "TODO\n",
    "- Widden Radius\n",
    "- Introduce Page scroll\n",
    "- Collect Relevant Items In DataFrame\n",
    "- Filter Those Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_listings = Google(\"Data Scientist\", \"Centennial Colorado\", 0)\n",
    "# google_listings = Google(\"Data Scientist\", \"remote\", 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
