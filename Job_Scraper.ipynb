{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8252cb",
   "metadata": {},
   "source": [
    "# Daily Jobs Web Scrapper\n",
    "3 titles I want to search across 4 platforms and google: Dice, Indeed, Monster, and Ziprecruiter.\n",
    "Can easily Create 5 seperate case class objects that extend a \"Search\" Abstraction, \n",
    "meaning each website will have to manual be instantiated\n",
    "\n",
    "## Vision\n",
    "Want to train an ai to webscrape unique websites (After:: already  exist routine based): \n",
    "\n",
    "### Obvious Limitations\n",
    "- Bott Checks, will have to first create an algorithm that can pass most \"Captcha\". \n",
    "\n",
    "- Misidentified parsing information\n",
    "\n",
    "- Invalid Selection Options, misunderstood from bott's perspective\n",
    "\n",
    "- User needed text inputs- outside of myself (Could create my own Brandon chat bott)\n",
    "\n",
    "#### Bott Checks\n",
    "Can have a categorizer for bott checks \n",
    "\n",
    "- Simple catchas can be waited then clicked \n",
    "**Need to start encorparating mouse movements in any scrapes**\n",
    "\n",
    "- Others can be sent back to vm and \"Solved\"- \n",
    "**Need to explore different algos for this probably a lot for most basics (Identify, right-side-up, etc.)**\n",
    "\n",
    "### Conclusion\n",
    "These limitations are vsat enough to put this part of the project on hold at the moment, maybe when I get more experience as a software engineer but this skillset will be pretty.. involved. \n",
    "\n",
    "#### Trouble Shooting\n",
    "Webdriver is shitty.. Most likely you are running this from the M1. \n",
    "\n",
    "First use brew to update your version of webdriver from terminal.\n",
    "For more,\n",
    "[Webdriver](\"https://stackoverflow.com/questions/76727774/selenium-webdriver-chrome-115-stopped-working/76731553#76731553\")\n",
    "\n",
    "    $ python3 -m pip install webdriver-manager \n",
    " \n",
    "Then update Splinter. \n",
    "For more,\n",
    "[Splinter](\"https://splinter.readthedocs.io/en/latest/why.html\")\n",
    "\n",
    "    $ python3 -m pip install splinter\n",
    "    \n",
    "Ideally note book was launched from a conda environment, \n",
    "\n",
    "**In the future start exporting your ymls and keep clean/distinct environment for each project**\n",
    "\n",
    "\n",
    "# Class Based Solution\n",
    "\n",
    "Abstraction, all websites will need\n",
    "\n",
    "- Basic navigation \n",
    "\n",
    "- Filtering of results in the website\n",
    "\n",
    "- Store job metadata as a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30405593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from JobBoard import *\n",
    "from Dice import Dice\n",
    "from Monster import Monster\n",
    "from Indeed import Indeed\n",
    "from LinkedIn import LinkedIn\n",
    "from ZipRecruiter import ZipRecruiter\n",
    "from Google import Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180e756",
   "metadata": {},
   "source": [
    "## Dice\n",
    "May want to consider a tiles approach, taking in all the raw data- unadolterated, then filtering instead of prefiltering on website\n",
    "\n",
    "TODO\n",
    "- Write Class Abstraction, Correctly write aggs and displays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3cd64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "days_ago = 0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "dice_listings = pd.concat([\n",
    "    Dice(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Engineer\", location, days_ago).available_jobs])\n",
    "\n",
    "location = \"remote\"\n",
    "\n",
    "remote_dice_listings = pd.concat([\n",
    "    Dice(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Dice(\"Data Engineer\", location, days_ago).available_jobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remote_dice_listings\\\n",
    "    .groupby([\"job_title\", \"company\"])\\\n",
    "    .count().reset_index()\n",
    "\n",
    "noSen = noSeniors(df)\n",
    "todays_date = \"Jan8\"\n",
    "\n",
    "noSen.sort_values(\"job_title\").to_csv(\"Remote_Jobs_\"+todays_date+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee34185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dice_listings\\\n",
    "    .groupby([\"job_title\", \"company\"]).sum()\\\n",
    "    .reset_index().sort_values(\"job_title\")\n",
    "\n",
    "noSeniors(df).head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15ba9a",
   "metadata": {},
   "source": [
    "## Indeed\n",
    "\n",
    "TODO\n",
    "\n",
    "- Fix clear sections on location\n",
    "- Integrate scroll and nextpage\n",
    "- Widden Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea54620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "days_ago=0\n",
    "location = \"Centennial\"\n",
    "\n",
    "indeed_listings = pd.concat([\n",
    "    Indeed(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Indeed(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Indeed(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Indeed(\"Data Engineer\", location, days_ago).available_jobs])\\\n",
    "    .reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c61f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_listings\\\n",
    "    .groupby([\"job_title\",\"company\"]).sum()\\\n",
    "    .reset_index().sort_values(\"job_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc375d",
   "metadata": {},
   "source": [
    "## LinkedIn\n",
    "TODO\n",
    "- Figure out next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0081711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "days_ago=0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "## Ran out of testing for today, Brokenish\n",
    "linkedin_jobs = pd.concat([\n",
    "    LinkedIn(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    LinkedIn(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    LinkedIn(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    LinkedIn(\"Data Engineer\", location, days_ago).available_jobs])\\\n",
    "    .reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1d574",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linkedin_jobs.sort_values(\"job_title\").reset_index()[[\"job_title\", \"company\", \"link\"]] # .iloc[7, 2]\n",
    "#     .groupby([\"job_title\",\"company\"]).sum()\\\n",
    "#     .reset_index().sort_values(\"job_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a77bc8",
   "metadata": {},
   "source": [
    "## Zip Recruiter\n",
    "TODO\n",
    "- Next Page\n",
    "- Bott Check in Parrallel, so can handle challenge if served (probably unneccessary if ran on daily cadence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375515e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_ago = 0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "zip_listings = pd.concat([\n",
    "    ZipRecruiter(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    ZipRecruiter(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    ZipRecruiter(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    ZipRecruiter(\"Data Engineer\", location, days_ago).available_jobs])\\\n",
    "    .reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d624cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65239c3",
   "metadata": {},
   "source": [
    "## Monster\n",
    "TODO\n",
    "- Widden Radius\n",
    "- Need to figure out python version errors with webdriver (only runs on Python 3, not python 3.11, could be because of depreciation on newer version- 3.11) find both python env (think alias Python 3 comes from conda) and resolve differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ce854",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_ago = 0\n",
    "location = \"Centennial Colorado\"\n",
    "\n",
    "monster_listings =  pd.concat([\n",
    "    Monster(\"SQL Analyst\", location, days_ago).available_jobs,\\\n",
    "    Monster(\"Data Analyst\", location, days_ago).available_jobs,\\\n",
    "    Monster(\"Data Scientist\", location, days_ago).available_jobs,\\\n",
    "    Monster(\"Data Engineer\", location, days_ago).available_jobs])\n",
    "len(monster_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0665cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped = pd.DataFrame(monster_listings)\\\n",
    "    .groupby([\"job_title\",\"company\"]).sum()\\\n",
    "    .reset_index().sort_values(\"job_title\")\n",
    "\n",
    "grouped.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.iloc[13, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee39cb",
   "metadata": {},
   "source": [
    "## Google\n",
    "TODO\n",
    "- Widden Radius\n",
    "- Introduce Page scroll\n",
    "- Collect Relevant Items In DataFrame\n",
    "- Filter Those Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_listings = Google(\"Data Scientist\", \"Centennial Colorado\", 0)\n",
    "# google_listings = Google(\"Data Scientist\", \"remote\", 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
